{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing word_counter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word_counter.py\n",
    "import os\n",
    "home=os.path.expanduser(\"~\")\n",
    "import findspark\n",
    "findspark.init(os.path.join(home,\"Downloads\",\"spark-2.0.0-bin-hadoop2.6\"))\n",
    "\n",
    "import pyspark\n",
    "myConf=pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession.builder.master(\"local\").appName(\"myApp\").config(conf=myConf).getOrCreate()\n",
    "\n",
    "myRdd2=spark.sparkContext\\\n",
    "    .textFile(os.path.join(\"data\",\"ds_spark_wiki.txt\"))\n",
    "\n",
    "wc2=myRdd2\\\n",
    "    .flatMap(lambda x:x.split())\\\n",
    "    .map(lambda x:(x,1))\\\n",
    "    .reduceByKey(lambda x,y:x+y)\\\n",
    "    .map(lambda x:(x[1],x[0]))\\\n",
    "    .sortByKey(False)\\\n",
    "    .take(10)\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "count = map(lambda x: x[0], wc2)\n",
    "word = map(lambda x: x[1], wc2)\n",
    "plt.barh(range(len(count)), count, color = 'grey')\n",
    "plt.yticks(range(len(count)), word)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
